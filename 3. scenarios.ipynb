{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2136fdf-4df1-4c9b-bb0f-72efdbf259dc",
   "metadata": {},
   "source": [
    "# Generation of exogenous variables scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f560167f-92c1-4d47-979d-5f9801d3568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gower  \n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b5aa4-082d-4521-bdc2-ddfd2d1755c1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ad32b2-b2bc-439c-b212-72fd8a24f7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>region</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>85.33</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>8173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 00:30:00</td>\n",
       "      <td>4.88</td>\n",
       "      <td>85.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>8173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>84.67</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>7944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 01:30:00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>84.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>7896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>83.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>7882.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  temperature  relative_humidity  apparent_temperature  \\\n",
       "0 2013-01-01 00:00:00         4.83              85.33                  1.03   \n",
       "1 2013-01-01 00:30:00         4.88              85.00                  1.07   \n",
       "2 2013-01-01 01:00:00         4.93              84.67                  1.10   \n",
       "3 2013-01-01 01:30:00         4.93              84.00                  1.08   \n",
       "4 2013-01-01 02:00:00         4.93              83.33                  1.07   \n",
       "\n",
       "   weather_code                region  consumption  \n",
       "0             2  Auvergne-Rhône-Alpes       8173.0  \n",
       "1             2  Auvergne-Rhône-Alpes       8173.0  \n",
       "2             2  Auvergne-Rhône-Alpes       7944.0  \n",
       "3             2  Auvergne-Rhône-Alpes       7896.0  \n",
       "4             2  Auvergne-Rhône-Alpes       7882.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53d483f-381a-4ae0-a0bf-a5fde8af1672",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46a67fa-4d0c-4436-843e-6dbce2fa2885",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['time'].dt.year <= 2019]\n",
    "test_data = data[data['time'].dt.year == 2020]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615cfb39-827b-4e36-a3c9-bc246ef0820f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Using weather_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8415362a-7e87-46f4-8222-aa290ef1ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenarios_code(data, region, date, n=5, k=3):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "\n",
    "    # Filter training data to include all dates before the provided date\n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature', 'weather_code']\n",
    "    \n",
    "    # Standardize the data before calculating distances\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "    \n",
    "        # Calculate Gower distances for each observation in test data compared to each observation in train subset\n",
    "        distances = gower.gower_matrix(scaled_test, scaled_train_subset)\n",
    "\n",
    "        # Select only the distances corresponding to element i of test with element i of scaled_train_subset\n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_test))]\n",
    "\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "\n",
    "    # Find the most similar previous days in the training dataset\n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "\n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "    similar_days = []\n",
    "\n",
    "    # Generate variations of plus/minus k periods of the following days to those similar days\n",
    "    for idx in real_indices:\n",
    "        day = train_data.iloc[idx:idx+48] # Take data from the next day with variations of ±k half hours\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                similar_days.append(day)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios, similar_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b094743-1b25-4908-8e38-ee2d30fd7087",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479387f0-bce1-4c30-a2cf-8195eb4ac780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenarios: 35\n",
      "\n",
      "---------------------------------------------------------- Real data ------------------------------------------------------------------------\n",
      "\n",
      "Today:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2019-01-01 00:00:00         6.60              88.33                  3.33             2 Auvergne-Rhône-Alpes       8984.0\n",
      "2019-01-01 00:30:00         6.38              89.17                  3.10             2 Auvergne-Rhône-Alpes       8815.0\n",
      "2019-01-01 01:00:00         6.17              90.00                  2.87             2 Auvergne-Rhône-Alpes       8576.0\n",
      "2019-01-01 01:30:00         5.90              91.17                  2.60             2 Auvergne-Rhône-Alpes       8526.0\n",
      "\n",
      "Tomorrow:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2019-01-02 00:00:00         4.70              83.33                  0.70             2 Auvergne-Rhône-Alpes       8591.0\n",
      "2019-01-02 00:30:00         4.85              82.33                  0.87             2 Auvergne-Rhône-Alpes       8372.0\n",
      "2019-01-02 01:00:00         5.00              81.33                  1.03             3 Auvergne-Rhône-Alpes       8119.0\n",
      "2019-01-02 01:30:00         4.92              83.00                  0.95             3 Auvergne-Rhône-Alpes       8089.0\n",
      "\n",
      "---------------------------------------------------------- Scenario 1 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2018-01-12 00:00:00         4.27              90.33                  0.73             0 Auvergne-Rhône-Alpes       9171.0\n",
      "2018-01-12 00:30:00         4.37              90.33                  1.00             0 Auvergne-Rhône-Alpes       8950.0\n",
      "2018-01-12 01:00:00         4.47              90.33                  1.27             1 Auvergne-Rhône-Alpes       8679.0\n",
      "2018-01-12 01:30:00         4.27              91.17                  1.00             1 Auvergne-Rhône-Alpes       8620.0\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2018-01-12 22:30:00         3.53              91.83                  0.58             1 Auvergne-Rhône-Alpes       9231.0\n",
      "2018-01-12 23:00:00         3.47              92.33                  0.67             1 Auvergne-Rhône-Alpes       9471.0\n",
      "2018-01-12 23:30:00         3.60              92.33                  0.88             1 Auvergne-Rhône-Alpes       9603.0\n",
      "2018-01-13 00:00:00         3.73              92.33                  1.10             2 Auvergne-Rhône-Alpes       9253.0\n",
      "\n",
      "---------------------------------------------------------- Scenario 2 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2018-01-12 00:00:00         4.27              90.33                  0.73             0 Auvergne-Rhône-Alpes       9171.0\n",
      "2018-01-12 00:30:00         4.37              90.33                  1.00             0 Auvergne-Rhône-Alpes       8950.0\n",
      "2018-01-12 01:00:00         4.47              90.33                  1.27             1 Auvergne-Rhône-Alpes       8679.0\n",
      "2018-01-12 01:30:00         4.27              91.17                  1.00             1 Auvergne-Rhône-Alpes       8620.0\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2018-01-12 23:00:00         3.47              92.33                  0.67             1 Auvergne-Rhône-Alpes       9471.0\n",
      "2018-01-12 23:30:00         3.60              92.33                  0.88             1 Auvergne-Rhône-Alpes       9603.0\n",
      "2018-01-13 00:00:00         3.73              92.33                  1.10             2 Auvergne-Rhône-Alpes       9253.0\n",
      "2018-01-13 00:30:00         3.52              93.33                  0.92             2 Auvergne-Rhône-Alpes       9036.0\n",
      "\n",
      "---------------------------------------------------------- Scenario 3 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2018-01-12 00:00:00         4.27              90.33                  0.73             0 Auvergne-Rhône-Alpes       9171.0\n",
      "2018-01-12 00:30:00         4.37              90.33                  1.00             0 Auvergne-Rhône-Alpes       8950.0\n",
      "2018-01-12 01:00:00         4.47              90.33                  1.27             1 Auvergne-Rhône-Alpes       8679.0\n",
      "2018-01-12 01:30:00         4.27              91.17                  1.00             1 Auvergne-Rhône-Alpes       8620.0\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption\n",
      "2018-01-12 23:30:00         3.60              92.33                  0.88             1 Auvergne-Rhône-Alpes       9603.0\n",
      "2018-01-13 00:00:00         3.73              92.33                  1.10             2 Auvergne-Rhône-Alpes       9253.0\n",
      "2018-01-13 00:30:00         3.52              93.33                  0.92             2 Auvergne-Rhône-Alpes       9036.0\n",
      "2018-01-13 01:00:00         3.30              94.33                  0.73             2 Auvergne-Rhône-Alpes       8713.0\n"
     ]
    }
   ],
   "source": [
    "# Example for Auvergne-Rhône-Alpes (2019-01-01)\n",
    "target_date = datetime.date(2019, 1, 1)\n",
    "scenarios, similar_days = generate_scenarios_code(train_data, 'Auvergne-Rhône-Alpes', target_date)\n",
    "\n",
    "print('Number of scenarios:', len(scenarios))\n",
    "\n",
    "print(\"\\n---------------------------------------------------------- Real data ------------------------------------------------------------------------\")\n",
    "Auvergne_data = train_data[train_data['region'] == 'Auvergne-Rhône-Alpes']\n",
    "print('\\nToday:')\n",
    "print(Auvergne_data[Auvergne_data['time'].dt.date == target_date].head(4).to_string(index=False))\n",
    "print('\\nTomorrow:')\n",
    "print(Auvergne_data[Auvergne_data['time'].dt.date == target_date + datetime.timedelta(days=1)].head(4).to_string(index=False))\n",
    "\n",
    "for i, escenario in enumerate(scenarios[:3]):\n",
    "    print(f\"\\n---------------------------------------------------------- Scenario {i+1} ------------------------------------------------------------------------\")\n",
    "    print('\\nSimilar day:')\n",
    "    print(similar_days[i].head(4).to_string(index=False)) \n",
    "    print('\\nNext day:')\n",
    "    print(escenario.head(4).to_string(index=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4bc3d-5fb1-4467-a37f-ecd928a7ea45",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e26be811-0b21-48ec-a0f2-bacd6e7962a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAPE: 8.22%\n"
     ]
    }
   ],
   "source": [
    "mapes = []\n",
    "real_consumption = Auvergne_data[Auvergne_data['time'].dt.date == target_date + datetime.timedelta(days=1)]['consumption'].values\n",
    "for i, escenario in enumerate(scenarios):\n",
    "    scenario_consumption = escenario['consumption'].values\n",
    "    mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "    mapes.append(mape)\n",
    "\n",
    "average_mape = np.mean(mapes)\n",
    "print(f\"Average MAPE: {average_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c9059-3569-4622-aaab-55fd6bf947ed",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Testing all the validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf07aa-77ba-4119-bc34-549df217ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = data['region'].unique()\n",
    "\n",
    "for region in regions:\n",
    "    mapes = []\n",
    "    \n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios, _ = generate_scenarios_code(train_data, region, date)\n",
    "        real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "        day_mapes = []\n",
    "        for i, scenario in enumerate(scenarios):\n",
    "            scenario_consumption = scenario['consumption'].values\n",
    "            mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "            day_mapes.append(mape)\n",
    "\n",
    "        average_day_mape = np.mean(day_mapes)\n",
    "        mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    print(f\"Average MAPE for {region}: {round(average_mape, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3834ded-78af-42dc-92c2-ca897f42c1e3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Parallelization\n",
    "\n",
    "Code executed in spyder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1af84d-36a2-479c-8966-1e02f5ede487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gower  \n",
    "\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "train_data = data[data['time'].dt.year <= 2019]\n",
    "test_data = data[data['time'].dt.year == 2020]  \n",
    "\n",
    "def generate_scenarios_code(data, region, date, n=5, k=3):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "\n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature', 'weather_code']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "    \n",
    "        distances = gower.gower_matrix(scaled_test, scaled_train_subset)\n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_train_subset))]\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "\n",
    "    for idx in real_indices:\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios\n",
    "\n",
    "def calculate_region_mape(region):\n",
    "    mapes = []\n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios = generate_scenarios_code(train_data, region, date)\n",
    "        real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "        if len(real_consumption) == 0:\n",
    "            continue\n",
    "\n",
    "        day_mapes = []\n",
    "        for scenario in scenarios:\n",
    "            scenario_consumption = scenario['consumption'].values\n",
    "            mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "            day_mapes.append(mape)\n",
    "\n",
    "        average_day_mape = np.mean(day_mapes)\n",
    "        mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    return (region, round(average_mape, 2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regions = data['region'].unique()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.map(calculate_region_mape, regions)\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Average MAPE for {result[0]}: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531595c-3e68-4b06-88cc-9826c79d211f",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "\n",
    "- Average MAPE for Auvergne-Rhône-Alpes: 11.2\n",
    "\n",
    "- Average MAPE for Bourgogne-Franche-Comté: 13.31\n",
    "\n",
    "- Average MAPE for Bretagne: 13.33\n",
    "\n",
    "- Average MAPE for Centre-Val de Loire: 12.96\n",
    "\n",
    "- Average MAPE for Grand-Est: 11.79\n",
    "\n",
    "- Average MAPE for Hauts-de-France: 10.07\n",
    "\n",
    "- Average MAPE for Ile-de-France: 11.65\n",
    "\n",
    "- Average MAPE for Normandie: 10.78\n",
    "\n",
    "- Average MAPE for Nouvelle-Aquitaine: 10.6\n",
    "\n",
    "- Average MAPE for Occitanie: 10.39\n",
    "\n",
    "- Average MAPE for PACA: 7.91\n",
    "\n",
    "- Average MAPE for Pays-de-la-Loire: 14.81\n",
    "\n",
    "<br>\n",
    "\n",
    "**Total average MAPE: 11.57**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fef334-9eee-4f31-b6b9-e2836f6aaaee",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "Currently, the 'weather_code' variable comprises nearly 100 distinct values. Let's see if our accuracy improves by grouping them based on the WMO code table: https://www.nodc.noaa.gov/archive/arc0021/0002199/1.1/data/0-data/HTML/WMO-CODE/WMO4677.HTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeb1a21-0f2b-4d23-9426-fa174573e21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>weather_code</th>\n",
       "      <th>region</th>\n",
       "      <th>consumption</th>\n",
       "      <th>weather_code_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 00:00:00</td>\n",
       "      <td>4.83</td>\n",
       "      <td>85.33</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>8173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 00:30:00</td>\n",
       "      <td>4.88</td>\n",
       "      <td>85.00</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>8173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 01:00:00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>84.67</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>7944.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 01:30:00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>84.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>7896.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 02:00:00</td>\n",
       "      <td>4.93</td>\n",
       "      <td>83.33</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time  temperature  relative_humidity  apparent_temperature  \\\n",
       "0 2013-01-01 00:00:00         4.83              85.33                  1.03   \n",
       "1 2013-01-01 00:30:00         4.88              85.00                  1.07   \n",
       "2 2013-01-01 01:00:00         4.93              84.67                  1.10   \n",
       "3 2013-01-01 01:30:00         4.93              84.00                  1.08   \n",
       "4 2013-01-01 02:00:00         4.93              83.33                  1.07   \n",
       "\n",
       "   weather_code                region  consumption  weather_code_group  \n",
       "0             2  Auvergne-Rhône-Alpes       8173.0                   0  \n",
       "1             2  Auvergne-Rhône-Alpes       8173.0                   0  \n",
       "2             2  Auvergne-Rhône-Alpes       7944.0                   0  \n",
       "3             2  Auvergne-Rhône-Alpes       7896.0                   0  \n",
       "4             2  Auvergne-Rhône-Alpes       7882.0                   0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_weather(code):\n",
    "    # No precipitation, fog, ice fog, duststorm, sandstorm, drifting or blowing snow \n",
    "    if code >= 0 and code <= 19: \n",
    "        return 0\n",
    "    # Precipitation, fog, ice fog or thunderstorm \n",
    "    elif code >= 20 and code <= 29:\n",
    "        return 1\n",
    "    # Duststorm, sandstorm, drifting or blowing snow\n",
    "    elif code >= 30 and code <= 39:\n",
    "        return 2\n",
    "    # Fog or ice fog at the time of observation\n",
    "    elif code >= 40 and code <= 49:\n",
    "        return 3\n",
    "    # Drizzle\n",
    "    elif code >= 50 and code <= 59:\n",
    "        return 4\n",
    "    # Rain\n",
    "    elif code >= 60 and code <= 69:\n",
    "        return 5\n",
    "    # Solid precipitation not in showers\n",
    "    elif code >= 70 and code <= 79:\n",
    "        return 6\n",
    "    # Showery precipitation or precipitation with current or recent thunderstorm\n",
    "    elif code >= 80 and code <= 99:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8 \n",
    "\n",
    "data['weather_code_group'] = data['weather_code'].apply(group_weather)\n",
    "train_data = data[data['time'].dt.year <= 2019]\n",
    "test_data = data[data['time'].dt.year == 2020]  \n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96782410-f989-4d95-8b8d-3ee94bffb0a8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01d2d20-e58f-482b-a883-701e65d6cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenarios_group(data, region, date, n=5, k=3):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "\n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature', 'weather_code_group']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "    \n",
    "        distances = gower.gower_matrix(scaled_test, scaled_train_subset)\n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_train_subset))]\n",
    "        \n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "    similar_days = []\n",
    "    \n",
    "    for idx in real_indices:\n",
    "        day = train_data.iloc[idx:idx+48] \n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                similar_days.append(day)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios, similar_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed77e3a-370b-41e7-bd77-7c2e77f181a6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3308aff8-31ce-41c9-8acd-51c06f0c1ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenarios: 35\n",
      "\n",
      "---------------------------------------------------------- Real data ------------------------------------------------------------------------\n",
      "\n",
      "Today:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2019-01-01 00:00:00         6.60              88.33                  3.33             2 Auvergne-Rhône-Alpes       8984.0                   0\n",
      "2019-01-01 00:30:00         6.38              89.17                  3.10             2 Auvergne-Rhône-Alpes       8815.0                   0\n",
      "2019-01-01 01:00:00         6.17              90.00                  2.87             2 Auvergne-Rhône-Alpes       8576.0                   0\n",
      "2019-01-01 01:30:00         5.90              91.17                  2.60             2 Auvergne-Rhône-Alpes       8526.0                   0\n",
      "\n",
      "Tomorrow:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2019-01-02 00:00:00         4.70              83.33                  0.70             2 Auvergne-Rhône-Alpes       8591.0                   0\n",
      "2019-01-02 00:30:00         4.85              82.33                  0.87             2 Auvergne-Rhône-Alpes       8372.0                   0\n",
      "2019-01-02 01:00:00         5.00              81.33                  1.03             3 Auvergne-Rhône-Alpes       8119.0                   0\n",
      "2019-01-02 01:30:00         4.92              83.00                  0.95             3 Auvergne-Rhône-Alpes       8089.0                   0\n",
      "\n",
      "---------------------------------------------------------- Scenario 1 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-01-12 00:00:00         4.27              90.33                  0.73             0 Auvergne-Rhône-Alpes       9171.0                   0\n",
      "2018-01-12 00:30:00         4.37              90.33                  1.00             0 Auvergne-Rhône-Alpes       8950.0                   0\n",
      "2018-01-12 01:00:00         4.47              90.33                  1.27             1 Auvergne-Rhône-Alpes       8679.0                   0\n",
      "2018-01-12 01:30:00         4.27              91.17                  1.00             1 Auvergne-Rhône-Alpes       8620.0                   0\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-01-12 22:30:00         3.53              91.83                  0.58             1 Auvergne-Rhône-Alpes       9231.0                   0\n",
      "2018-01-12 23:00:00         3.47              92.33                  0.67             1 Auvergne-Rhône-Alpes       9471.0                   0\n",
      "2018-01-12 23:30:00         3.60              92.33                  0.88             1 Auvergne-Rhône-Alpes       9603.0                   0\n",
      "2018-01-13 00:00:00         3.73              92.33                  1.10             2 Auvergne-Rhône-Alpes       9253.0                   0\n",
      "\n",
      "---------------------------------------------------------- Scenario 2 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-01-12 00:00:00         4.27              90.33                  0.73             0 Auvergne-Rhône-Alpes       9171.0                   0\n",
      "2018-01-12 00:30:00         4.37              90.33                  1.00             0 Auvergne-Rhône-Alpes       8950.0                   0\n",
      "2018-01-12 01:00:00         4.47              90.33                  1.27             1 Auvergne-Rhône-Alpes       8679.0                   0\n",
      "2018-01-12 01:30:00         4.27              91.17                  1.00             1 Auvergne-Rhône-Alpes       8620.0                   0\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-01-12 23:00:00         3.47              92.33                  0.67             1 Auvergne-Rhône-Alpes       9471.0                   0\n",
      "2018-01-12 23:30:00         3.60              92.33                  0.88             1 Auvergne-Rhône-Alpes       9603.0                   0\n",
      "2018-01-13 00:00:00         3.73              92.33                  1.10             2 Auvergne-Rhône-Alpes       9253.0                   0\n",
      "2018-01-13 00:30:00         3.52              93.33                  0.92             2 Auvergne-Rhône-Alpes       9036.0                   0\n",
      "\n",
      "---------------------------------------------------------- Scenario 3 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-01-12 00:00:00         4.27              90.33                  0.73             0 Auvergne-Rhône-Alpes       9171.0                   0\n",
      "2018-01-12 00:30:00         4.37              90.33                  1.00             0 Auvergne-Rhône-Alpes       8950.0                   0\n",
      "2018-01-12 01:00:00         4.47              90.33                  1.27             1 Auvergne-Rhône-Alpes       8679.0                   0\n",
      "2018-01-12 01:30:00         4.27              91.17                  1.00             1 Auvergne-Rhône-Alpes       8620.0                   0\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-01-12 23:30:00         3.60              92.33                  0.88             1 Auvergne-Rhône-Alpes       9603.0                   0\n",
      "2018-01-13 00:00:00         3.73              92.33                  1.10             2 Auvergne-Rhône-Alpes       9253.0                   0\n",
      "2018-01-13 00:30:00         3.52              93.33                  0.92             2 Auvergne-Rhône-Alpes       9036.0                   0\n",
      "2018-01-13 01:00:00         3.30              94.33                  0.73             2 Auvergne-Rhône-Alpes       8713.0                   0\n"
     ]
    }
   ],
   "source": [
    "# Example for Auvergne-Rhône-Alpes (2019-01-01)\n",
    "target_date = datetime.date(2019, 1, 1)\n",
    "scenarios, similar_days = generate_scenarios_group(train_data, 'Auvergne-Rhône-Alpes', target_date)\n",
    "\n",
    "print('Number of scenarios:', len(scenarios))\n",
    "\n",
    "print(\"\\n---------------------------------------------------------- Real data ------------------------------------------------------------------------\")\n",
    "Auvergne_data = train_data[train_data['region'] == 'Auvergne-Rhône-Alpes']\n",
    "print('\\nToday:')\n",
    "print(Auvergne_data[Auvergne_data['time'].dt.date == target_date].head(4).to_string(index=False))\n",
    "print('\\nTomorrow:')\n",
    "print(Auvergne_data[Auvergne_data['time'].dt.date == target_date + datetime.timedelta(days=1)].head(4).to_string(index=False))\n",
    "\n",
    "for i, escenario in enumerate(scenarios[:3]):\n",
    "    print(f\"\\n---------------------------------------------------------- Scenario {i+1} ------------------------------------------------------------------------\")\n",
    "    print('\\nSimilar day:')\n",
    "    print(similar_days[i].head(4).to_string(index=False)) \n",
    "    print('\\nNext day:')\n",
    "    print(escenario.head(4).to_string(index=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239e01d-6533-402f-9d30-6cc34bdb71c8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225c4c2f-1d33-4f8b-a4d1-91b1595db76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAPE: 5.96%\n"
     ]
    }
   ],
   "source": [
    "mapes = []\n",
    "real_consumption = Auvergne_data[Auvergne_data['time'].dt.date == target_date + datetime.timedelta(days=1)]['consumption'].values\n",
    "\n",
    "for i, escenario in enumerate(scenarios):\n",
    "    scenario_consumption = escenario['consumption'].values\n",
    "    mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "    mapes.append(mape)\n",
    "\n",
    "average_mape = np.mean(mapes)\n",
    "print(f\"Average MAPE: {average_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e772640-45ce-4733-a188-91616d06db72",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Testing all the validation test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146c59e-5743-4b9f-b1b9-79eca3cf5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = data['region'].unique()\n",
    "\n",
    "for region in regions:\n",
    "    mapes = []\n",
    "    \n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios, _ = generate_scenarios_group(train_data, region, date)\n",
    "        real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "        day_mapes = []\n",
    "        for i, scenario in enumerate(scenarios):\n",
    "            scenario_consumption = scenario['consumption'].values\n",
    "            mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "            day_mapes.append(mape)\n",
    "\n",
    "        average_day_mape = np.mean(day_mapes)\n",
    "        mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    print(f\"Average MAPE for {region}: {round(average_mape, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83362d5-77d9-476b-b2da-393c427832f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Parallelization\n",
    "\n",
    "Code executed in spyder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625cb238-3cb7-4b64-b53c-3e6781a6770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gower  \n",
    "\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "def group_weather(code):\n",
    "    if code >= 0 and code <= 19: \n",
    "        return 0\n",
    "    elif code >= 20 and code <= 29:\n",
    "        return 1\n",
    "    elif code >= 30 and code <= 39:\n",
    "        return 2\n",
    "    elif code >= 40 and code <= 49:\n",
    "        return 3\n",
    "    elif code >= 50 and code <= 59:\n",
    "        return 4\n",
    "    elif code >= 60 and code <= 69:\n",
    "        return 5\n",
    "    elif code >= 70 and code <= 79:\n",
    "        return 6\n",
    "    elif code >= 80 and code <= 99:\n",
    "        return 7\n",
    "    else:\n",
    "        return 8 \n",
    "\n",
    "data['weather_code_group'] = data['weather_code'].apply(group_weather)\n",
    "\n",
    "train_data = data[data['time'].dt.year <= 2019]\n",
    "test_data = data[data['time'].dt.year == 2020]  \n",
    "\n",
    "def generate_scenarios_group(data, region, date, n=5, k=3):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "\n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature', 'weather_code_group']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "\n",
    "        distances = gower.gower_matrix(scaled_test, scaled_train_subset)\n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_train_subset))]\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "\n",
    "    for idx in real_indices:\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios\n",
    "\n",
    "def calculate_region_mape(region):\n",
    "    mapes = []\n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios = generate_scenarios_group(train_data, region, date)\n",
    "        real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "        if len(real_consumption) == 0:\n",
    "            continue\n",
    "                    \n",
    "        day_mapes = []\n",
    "        for scenario in scenarios:\n",
    "            scenario_consumption = scenario['consumption'].values\n",
    "            mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "            day_mapes.append(mape)\n",
    "\n",
    "        average_day_mape = np.mean(day_mapes)\n",
    "        mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    return (region, round(average_mape, 2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regions = data['region'].unique()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.map(calculate_region_mape, regions)\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Average MAPE for {result[0]}: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae2a66-c87e-4674-97ea-1f89f902ba30",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "\n",
    "- Average MAPE for Auvergne-Rhône-Alpes: 10.91\n",
    "\n",
    "- Average MAPE for Bourgogne-Franche-Comté: 13.33\n",
    "\n",
    "- Average MAPE for Bretagne: 13.4\n",
    "\n",
    "- Average MAPE for Centre-Val de Loire: 12.79\n",
    "\n",
    "- Average MAPE for Grand-Est: 11.84\n",
    "\n",
    "- Average MAPE for Hauts-de-France: 10.13\n",
    "\n",
    "- Average MAPE for Ile-de-France: 11.67\n",
    "\n",
    "- Average MAPE for Normandie: 10.84\n",
    "\n",
    "- Average MAPE for Nouvelle-Aquitaine: 10.58\n",
    "\n",
    "- Average MAPE for Occitanie: 10.16\n",
    "\n",
    "- Average MAPE for PACA: 7.72\n",
    "\n",
    "- Average MAPE for Pays-de-la-Loire: 14.46\n",
    "\n",
    "<br>\n",
    "\n",
    "**Total average MAPE: 11.48**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e97a12-51a6-4a9d-9874-ac5069e6b8a9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Not using weather_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a3ecec-56a8-44a8-aef8-7b3fbf8d3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenarios_no_code(data, region, date, n=5, k=3):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "\n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "    \n",
    "        distances = gower.gower_matrix(scaled_test, scaled_train_subset)\n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_test))]\n",
    "\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "        \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "    similar_days = []\n",
    "    \n",
    "    for idx in real_indices:\n",
    "        day = train_data.iloc[idx:idx+48] \n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                similar_days.append(day)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios, similar_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba8426-304c-4cbb-989d-4a927d5bd9f7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1acbdac-3e9b-4afc-a978-183b130e3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scenarios: 35\n",
      "\n",
      "---------------------------------------------------------- Real data ------------------------------------------------------------------------\n",
      "\n",
      "Today:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2018-12-31 00:00:00         4.57              86.33                  1.07             2 Auvergne-Rhône-Alpes       9066.0                   0\n",
      "2018-12-31 00:30:00         4.48              86.33                  1.10             2 Auvergne-Rhône-Alpes       8868.0                   0\n",
      "2018-12-31 01:00:00         4.40              86.33                  1.13             2 Auvergne-Rhône-Alpes       8641.0                   0\n",
      "2018-12-31 01:30:00         4.35              86.67                  1.10             2 Auvergne-Rhône-Alpes       8623.0                   0\n",
      "\n",
      "Tomorrow:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2019-01-01 00:00:00         6.60              88.33                  3.33             2 Auvergne-Rhône-Alpes       8984.0                   0\n",
      "2019-01-01 00:30:00         6.38              89.17                  3.10             2 Auvergne-Rhône-Alpes       8815.0                   0\n",
      "2019-01-01 01:00:00         6.17              90.00                  2.87             2 Auvergne-Rhône-Alpes       8576.0                   0\n",
      "2019-01-01 01:30:00         5.90              91.17                  2.60             2 Auvergne-Rhône-Alpes       8526.0                   0\n",
      "\n",
      "---------------------------------------------------------- Scenario 1 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2017-03-05 00:00:00         4.17              90.33                  0.87             3 Auvergne-Rhône-Alpes       8423.0                   0\n",
      "2017-03-05 00:30:00         4.28              89.17                  1.00            11 Auvergne-Rhône-Alpes       8240.0                   0\n",
      "2017-03-05 01:00:00         4.40              88.00                  1.13            19 Auvergne-Rhône-Alpes       7958.0                   0\n",
      "2017-03-05 01:30:00         4.45              87.17                  1.20            27 Auvergne-Rhône-Alpes       7880.0                   1\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2017-03-05 22:30:00         6.03              88.00                  2.75            29 Auvergne-Rhône-Alpes       8402.0                   1\n",
      "2017-03-05 23:00:00         5.97              88.00                  2.87            19 Auvergne-Rhône-Alpes       8682.0                   0\n",
      "2017-03-05 23:30:00         5.73              89.33                  2.63            19 Auvergne-Rhône-Alpes       8807.0                   0\n",
      "2017-03-06 00:00:00         5.50              90.67                  2.40            20 Auvergne-Rhône-Alpes       8493.0                   1\n",
      "\n",
      "---------------------------------------------------------- Scenario 2 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2017-03-05 00:00:00         4.17              90.33                  0.87             3 Auvergne-Rhône-Alpes       8423.0                   0\n",
      "2017-03-05 00:30:00         4.28              89.17                  1.00            11 Auvergne-Rhône-Alpes       8240.0                   0\n",
      "2017-03-05 01:00:00         4.40              88.00                  1.13            19 Auvergne-Rhône-Alpes       7958.0                   0\n",
      "2017-03-05 01:30:00         4.45              87.17                  1.20            27 Auvergne-Rhône-Alpes       7880.0                   1\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2017-03-05 23:00:00         5.97              88.00                  2.87            19 Auvergne-Rhône-Alpes       8682.0                   0\n",
      "2017-03-05 23:30:00         5.73              89.33                  2.63            19 Auvergne-Rhône-Alpes       8807.0                   0\n",
      "2017-03-06 00:00:00         5.50              90.67                  2.40            20 Auvergne-Rhône-Alpes       8493.0                   1\n",
      "2017-03-06 00:30:00         5.55              90.50                  2.35            20 Auvergne-Rhône-Alpes       8297.0                   1\n",
      "\n",
      "---------------------------------------------------------- Scenario 3 ------------------------------------------------------------------------\n",
      "\n",
      "Similar day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2017-03-05 00:00:00         4.17              90.33                  0.87             3 Auvergne-Rhône-Alpes       8423.0                   0\n",
      "2017-03-05 00:30:00         4.28              89.17                  1.00            11 Auvergne-Rhône-Alpes       8240.0                   0\n",
      "2017-03-05 01:00:00         4.40              88.00                  1.13            19 Auvergne-Rhône-Alpes       7958.0                   0\n",
      "2017-03-05 01:30:00         4.45              87.17                  1.20            27 Auvergne-Rhône-Alpes       7880.0                   1\n",
      "\n",
      "Next day:\n",
      "               time  temperature  relative_humidity  apparent_temperature  weather_code               region  consumption  weather_code_group\n",
      "2017-03-05 23:30:00         5.73              89.33                  2.63            19 Auvergne-Rhône-Alpes       8807.0                   0\n",
      "2017-03-06 00:00:00         5.50              90.67                  2.40            20 Auvergne-Rhône-Alpes       8493.0                   1\n",
      "2017-03-06 00:30:00         5.55              90.50                  2.35            20 Auvergne-Rhône-Alpes       8297.0                   1\n",
      "2017-03-06 01:00:00         5.60              90.33                  2.30            20 Auvergne-Rhône-Alpes       8010.0                   1\n"
     ]
    }
   ],
   "source": [
    "# Example for Auvergne-Rhône-Alpes (2019-01-01)\n",
    "target_date = datetime.date(2019, 1, 1)\n",
    "scenarios, similar_days = generate_scenarios_no_code(train_data, 'Auvergne-Rhône-Alpes', target_date)\n",
    "\n",
    "print('Number of scenarios:', len(scenarios))\n",
    "\n",
    "print(\"\\n---------------------------------------------------------- Real data ------------------------------------------------------------------------\")\n",
    "Auvergne_data = train_data[train_data['region'] == 'Auvergne-Rhône-Alpes']\n",
    "print('\\nToday:')\n",
    "print(Auvergne_data[Auvergne_data['time'].dt.date == target_date - datetime.timedelta(days=1)].head(4).to_string(index=False))\n",
    "print('\\nTomorrow:')\n",
    "print(Auvergne_data[Auvergne_data['time'].dt.date == target_date].head(4).to_string(index=False))\n",
    "\n",
    "for i, escenario in enumerate(scenarios[:3]):\n",
    "    print(f\"\\n---------------------------------------------------------- Scenario {i+1} ------------------------------------------------------------------------\")\n",
    "    print('\\nSimilar day:')\n",
    "    print(similar_days[i].head(4).to_string(index=False)) \n",
    "    print('\\nNext day:')\n",
    "    print(escenario.head(4).to_string(index=False)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c3c47-a7f1-41e2-ab3a-dae30cd42b18",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b65fb89-be0b-4e42-a3bf-08682578dea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAPE: 5.55%\n"
     ]
    }
   ],
   "source": [
    "mapes = []\n",
    "real_consumption = Auvergne_data[Auvergne_data['time'].dt.date == target_date + datetime.timedelta(days=1)]['consumption'].values\n",
    "\n",
    "for i, escenario in enumerate(scenarios):\n",
    "    scenario_consumption = escenario['consumption'].values\n",
    "    mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "    mapes.append(mape)\n",
    "\n",
    "average_mape = np.mean(mapes)\n",
    "print(f\"Average MAPE: {average_mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdea851-0fca-49f2-aa5f-fde88db0753a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Testing all the validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc1d02-2736-4674-a2ab-a37eb2ac0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = data['region'].unique()\n",
    "\n",
    "for region in regions:\n",
    "    mapes = []\n",
    "    \n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios, _ = generate_scenarios_no_code(train_data, region, date)\n",
    "        real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "        day_mapes = []\n",
    "        for i, scenario in enumerate(scenarios):\n",
    "            scenario_consumption = scenario['consumption'].values\n",
    "            mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "            day_mapes.append(mape)\n",
    "\n",
    "        average_day_mape = np.mean(day_mapes)\n",
    "        mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    print(f\"Average MAPE for {region}: {round(average_mape, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863abc80-b97f-4273-9f04-f787fbd844b6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Parallelization\n",
    "\n",
    "Code executed in spyder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12caa935-b135-4c19-83b9-0fbc9805dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gower  \n",
    "\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "train_data = data[data['time'].dt.year <= 2019]\n",
    "test_data = data[data['time'].dt.year == 2020]  \n",
    "\n",
    "def generate_scenarios_no_code(data, region, date, n=5, k=3):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "    \n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "\n",
    "        distances = gower.gower_matrix(scaled_test, scaled_train_subset)\n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_train_subset))]\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "\n",
    "    for idx in real_indices:\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios\n",
    "\n",
    "def calculate_region_mape(region):\n",
    "    mapes = []\n",
    "    start_date = datetime.date(2019, 1, 1)\n",
    "    end_date = datetime.date(2019, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios = generate_scenarios_no_code(train_data, region, date)\n",
    "        real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "        if len(real_consumption) == 0:\n",
    "            continue\n",
    "                    \n",
    "        day_mapes = []\n",
    "        for scenario in scenarios:\n",
    "            scenario_consumption = scenario['consumption'].values\n",
    "            mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "            day_mapes.append(mape)\n",
    "\n",
    "        average_day_mape = np.mean(day_mapes)\n",
    "        mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    return (region, round(average_mape, 2))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regions = data['region'].unique()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.map(calculate_region_mape, regions)\n",
    "\n",
    "    for result in results:\n",
    "        print(f\"Average MAPE for {result[0]}: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5b6f0-b85e-4bf5-926d-d3802a005acd",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "\n",
    "- Average MAPE for Auvergne-Rhône-Alpes: 10.92\n",
    "\n",
    "- Average MAPE for Bourgogne-Franche-Comté: 13.43\n",
    "\n",
    "- Average MAPE for Bretagne: 13.35\n",
    "\n",
    "- Average MAPE for Centre-Val de Loire: 13.06\n",
    "\n",
    "- Average MAPE for Grand-Est: 11.69\n",
    "\n",
    "- Average MAPE for Hauts-de-France: 10.17\n",
    "\n",
    "- Average MAPE for Ile-de-France: 11.79\n",
    "\n",
    "- Average MAPE for Normandie: 10.77\n",
    "\n",
    "- Average MAPE for Nouvelle-Aquitaine: 10.52\n",
    "\n",
    "- Average MAPE for Occitanie: 10.29\n",
    "\n",
    "- Average MAPE for PACA: 7.76\n",
    "\n",
    "- Average MAPE for Pays-de-la-Loire: 14.37\n",
    "\n",
    "<br>\n",
    "\n",
    "**Total average MAPE: 11.51**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9f5959-f899-480c-b426-9a69570dab34",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "|              | With 'weather_code' | With 'weather_code_group' | Without 'weather_code' |\n",
    "|--------------|------------------|------------------------|------------------|\n",
    "| MAPE         |       11.57          |         11.48               |      11.51            |\n",
    "\n",
    "<br>\n",
    "\n",
    "**Best approach**: With 'weather_code_group'.\n",
    "\n",
    "However, as the results using or not 'weather_code_group' are nearly identical, **we will not include these variables** in our analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386fa18-a51c-41ca-8ea1-69469d4078e8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7af8c370-6fc0-4c6b-92fa-314502a461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenarios(data, region, date, n, k, dist):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "    \n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "\n",
    "        distances = cdist(scaled_test[features], scaled_train_subset[features], metric=dist) \n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_train_subset))]\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "\n",
    "    for idx in real_indices:\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c9192-02e6-4849-9814-ee5629335108",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65dfad-c5a7-4a5c-a255-07eca016c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n': [3, 5, 7],\n",
    "        'k': [1, 3, 5],\n",
    "        'dist': ['euclidean', 'cityblock']\n",
    "    }\n",
    "\n",
    "param_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_mape = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for params in param_combinations:\n",
    "    mapes = []\n",
    "    \n",
    "    for region in regions:\n",
    "        start_date = datetime.date(2019, 1, 1)\n",
    "        end_date = datetime.date(2019, 12, 31)\n",
    "        validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "        \n",
    "        for date in validation_dates:\n",
    "            scenarios, _ = generate_scenarios(train_data, region, date, n=params['n'], k=params['k'])\n",
    "            real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "            day_mapes = []\n",
    "            for scenario in scenarios:\n",
    "                scenario_consumption = scenario['consumption'].values\n",
    "                mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "                day_mapes.append(mape)\n",
    "\n",
    "            average_day_mape = np.mean(day_mapes)\n",
    "            mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    print(f\"Parameters: {params}, MAPE: {average_mape}\")\n",
    "    \n",
    "    if average_mape < best_mape:\n",
    "        best_mape = average_mape\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best MAPE:\", best_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01081cc1-27f9-4b4d-af5c-7e43adac3b61",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Parallelization\n",
    "\n",
    "Code executed in spyder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09ca47-cb59-477f-8b60-277cdf810533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "train_data = data[data['time'].dt.year <= 2019]\n",
    "test_data = data[data['time'].dt.year == 2020]  \n",
    "\n",
    "def generate_scenarios(data, region, date, n, k, dist):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "    \n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "\n",
    "        distances = cdist(scaled_test[features], scaled_train_subset[features], metric=dist) \n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_train_subset))]\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "\n",
    "    for idx in real_indices:\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios\n",
    "\n",
    "def calculate_mape_for_params(params, regions, train_data):\n",
    "    mapes = []\n",
    "    for region in regions:\n",
    "        start_date = datetime.date(2019, 1, 1)\n",
    "        end_date = datetime.date(2019, 12, 31)\n",
    "        validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "        \n",
    "        for date in validation_dates:\n",
    "            scenarios = generate_scenarios(train_data, region, date, n=params['n'], k=params['k'], dist=params['dist'])\n",
    "            real_consumption = train_data[(train_data['region'] == region) & (train_data['time'].dt.date == date + datetime.timedelta(days=1))]['consumption'].values\n",
    "\n",
    "            if len(real_consumption) == 0:\n",
    "                continue\n",
    "                    \n",
    "            day_mapes = []\n",
    "            for scenario in scenarios:\n",
    "                scenario_consumption = scenario['consumption'].values\n",
    "                mape = np.mean(np.abs((real_consumption - scenario_consumption) / real_consumption)) * 100\n",
    "                day_mapes.append(mape)\n",
    "\n",
    "            average_day_mape = np.mean(day_mapes)\n",
    "            mapes.append(average_day_mape)\n",
    "\n",
    "    average_mape = np.mean(mapes)\n",
    "    print(f\"Parameters: {params}, MAPE: {average_mape}\")\n",
    "    return average_mape\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regions = data['region'].unique()\n",
    "    \n",
    "    param_grid = {\n",
    "        'n': [3, 5, 7],\n",
    "        'k': [1, 3, 5],\n",
    "        'dist': ['euclidean', 'cityblock']\n",
    "    }\n",
    "    \n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    best_mape = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.starmap(calculate_mape_for_params, [(params, regions, train_data) for params in param_combinations])\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if result < best_mape:\n",
    "            best_mape = result\n",
    "            best_params = param_combinations[i]\n",
    "    \n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best MAPE:\", best_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736bda44-bf5a-4c5c-8fac-0a0fff5b78d1",
   "metadata": {},
   "source": [
    "**Output**:\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 1, 'n': 3}, MAPE: 11.09\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 1, 'n': 5}, MAPE: 11.11\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 1, 'n': 7}, MAPE: 11.12\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 3, 'n': 3}, MAPE: 11.63\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 3, 'n': 5}, MAPE: 11.65\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 3, 'n': 7}, MAPE: 11.66\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 5, 'n': 3}, MAPE: 12.25\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 5, 'n': 5}, MAPE: 12.26\n",
    "\n",
    "- Parameters: {'dist': 'euclidean', 'k': 5, 'n': 7}, MAPE: 12.28\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 1, 'n': 3}, MAPE: **10.99**\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 1, 'n': 5}, MAPE: 11.04\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 1, 'n': 7}, MAPE: 11.05\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 3, 'n': 3}, MAPE: 11.54\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 3, 'n': 5}, MAPE: 11.59\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 3, 'n': 7}, MAPE: 11.60\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 5, 'n': 3}, MAPE: 12.16\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 5, 'n': 5}, MAPE: 12.21\n",
    "\n",
    "- Parameters: {'dist': 'cityblock', 'k': 5, 'n': 7}, MAPE: 12.22\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "**Best parameters: {'dist': 'cityblock', 'k': 1, 'n': 3}**\n",
    "\n",
    "**Best MAPE: 10.99**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152c8c-7585-487e-80cb-6d278d9c148b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Generation of scenarios with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4343c-270b-4d68-aaaa-589ac979cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = data['region'].unique()\n",
    "\n",
    "scenarios_final = {}\n",
    "for region in regions:  \n",
    "    start_date = datetime.date(2020, 1, 1)\n",
    "    end_date = datetime.date(2020, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios = generate_scenarios(train_data, region, date, 3, 1, 'cityblock')\n",
    "        scenarios_final[(region, date)] = scenarios\n",
    "\n",
    "with open('scenarios_final.pkl', 'wb') as scenarios_file:\n",
    "    pickle.dump(scenarios_final, scenarios_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0d67e-2fe6-4963-ba07-910fda507a9f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Parallelization\n",
    "\n",
    "Code executed in spyder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efc347-548b-4206-9010-d27a9a07e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "data = pd.read_csv(\"final_data.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "def generate_scenarios(data, region, date, n, k, dist):\n",
    "    region_data = data[data['region'] == region]\n",
    "    previous_day = date - datetime.timedelta(days=1)\n",
    "    \n",
    "    train_data = region_data[region_data['time'].dt.date < previous_day]\n",
    "    test = region_data[region_data['time'].dt.date == previous_day]\n",
    "\n",
    "    features = ['temperature', 'relative_humidity', 'apparent_temperature']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_train_data = scaler.fit_transform(train_data[features])\n",
    "    scaled_test = scaler.transform(test[features])\n",
    "    \n",
    "    scaled_train_data = pd.DataFrame(scaled_train_data, columns=features)\n",
    "    scaled_train_data[features] = scaled_train_data[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    scaled_test = pd.DataFrame(scaled_test, columns=features)\n",
    "    scaled_test[features] = scaled_test[features].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    day_distances = []\n",
    "    for i in range(int(len(train_data)/48)):\n",
    "        scaled_train_subset = scaled_train_data.iloc[i*48:(i+1)*48]\n",
    "        distances = cdist(scaled_test, scaled_train_subset, metric=dist) \n",
    "        element_distances = distances[np.arange(len(scaled_test)), np.arange(len(scaled_test))]\n",
    "        sum_distance = np.sum(element_distances)\n",
    "        day_distances.append(sum_distance)\n",
    "\n",
    "    day_distances = np.array(day_distances)\n",
    "   \n",
    "    similar_indices = np.argsort(day_distances)[:n*2] \n",
    "    real_indices = [idx*48 for idx in similar_indices]\n",
    "    \n",
    "    n_scenarios = n*(2*k+1)\n",
    "    scenarios = []\n",
    "\n",
    "    for idx in real_indices:\n",
    "        for i in range(48-k, 48+k+1):\n",
    "            variation = train_data.iloc[idx+i:idx+i+48] \n",
    "            if len(variation) == 48:  \n",
    "                scenarios.append(variation)\n",
    "                   \n",
    "            if len(scenarios) >= n_scenarios:\n",
    "                break\n",
    "            \n",
    "        if len(scenarios) >= n_scenarios:\n",
    "            break\n",
    "            \n",
    "    return scenarios\n",
    "\n",
    "def calculate_region_scenarios(region):\n",
    "    scenarios_final = {}\n",
    "    start_date = datetime.date(2020, 1, 1)\n",
    "    end_date = datetime.date(2020, 12, 31)\n",
    "    validation_dates = [start_date + datetime.timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    for date in validation_dates:\n",
    "        scenarios = generate_scenarios(data, region, date, 3, 1, 'cityblock')\n",
    "        scenarios_final[(region, date)] = scenarios\n",
    "\n",
    "    return scenarios_final\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    regions = data['region'].unique()\n",
    "    \n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.map(calculate_region_scenarios, regions)\n",
    "\n",
    "    all_scenarios = {}  \n",
    "    \n",
    "    for region_scenarios in results:\n",
    "        all_scenarios.update(region_scenarios)\n",
    "\n",
    "    with open('scenarios_final.pkl', 'wb') as scenarios_file:\n",
    "        pickle.dump(all_scenarios, scenarios_file)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
